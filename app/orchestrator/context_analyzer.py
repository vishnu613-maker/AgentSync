"""
Context Analyzer for AgentSync Orchestrator
Implements 3-tier context resolution:
  Tier 1: Check if user input has sufficient context
  Tier 2: Search ChromaDB for relevant context
  Tier 3: Request context from other agents
  Tier 4: Generate user feedback for missing context
"""
import logging
import json
import re
from typing import Dict, Any, Optional, List, Tuple

from app.services.llm_service import LLMService
from app.services.context_retrieval_service import get_context_retrieval_service
from app.agents.registry import agent_registry
from app.config import get_settings

logger = logging.getLogger(__name__)


class ContextAnalyzer:
    """
    Analyzes user input and manages context enrichment
    Implements intelligent context resolution workflow
    """
    
    def __init__(self, llm_service: LLMService):
        """
        Initialize context analyzer
        
        Args:
            llm_service: LLM service for context analysis
        """
        self.llm_service = llm_service
        self.retrieval_service = get_context_retrieval_service()
        self.settings = get_settings()
        self.model = "phi3.5:latest"
        logger.info("[CONTEXT_ANALYZER] Initialized")
    
    async def analyze_context_needs(
        self,
        user_input: str,
        agent_name: str,
        action: str,
        available_tools: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        TIER 1: Analyze if user input has sufficient context for the action
        
        Args:
            user_input: User's natural language input
            agent_name: Target agent (tasks, email, calendar, etc.)
            action: Specific action to perform (create_task, send_email, etc.)
            available_tools: List of available tools with their parameters
        
        Returns:
            {
                "need_context": bool,
                "action": str (if sufficient),
                "instructions": str (if sufficient),
                "query": str (if needs context),
                "missing_params": List[str] (if needs context),
                "reason": str
            }
        """
        logger.info(f"[CONTEXT_ANALYZER] Analyzing context needs for {agent_name}.{action}")
        logger.info(f"[CONTEXT_ANALYZER] User input: {user_input}")
        
        # Find tool definition
        tool_info = self._get_tool_info(available_tools, action)
        
        if not tool_info:
            logger.warning(f"[CONTEXT_ANALYZER] Tool not found: {action}")
            return {
                "need_context": False,
                "action": action,
                "instructions": user_input,
                "reason": "Tool definition not found, proceeding with user input"
            }
        
        # Build analysis prompt
        prompt = self._build_context_analysis_prompt(
            user_input=user_input,
            agent_name=agent_name,
            action=action,
            tool_info=tool_info
        )
        
        # Call LLM for analysis
        try:
            response = await self.llm_service.call_ollama(
                model_name=self.model,
                prompt=prompt
            )
            
            logger.info(f"[CONTEXT_ANALYZER] LLM Response: {response}")
            
            # Parse JSON response
            analysis = self._parse_llm_response(response)
            
            if analysis:
                logger.info(f"[CONTEXT_ANALYZER] ✅ Analysis complete: need_context={analysis.get('need_context')}")
                return analysis
            else:
                # Fallback if parsing fails
                logger.warning("[CONTEXT_ANALYZER] Failed to parse LLM response, assuming sufficient context")
                return {
                    "need_context": False,
                    "action": action,
                    "instructions": user_input,
                    "reason": "Parse error, proceeding with user input"
                }
                
        except Exception as e:
            logger.error(f"[CONTEXT_ANALYZER] ❌ Error during analysis: {e}", exc_info=True)
            return {
                "need_context": False,
                "action": action,
                "instructions": user_input,
                "reason": f"Analysis error: {str(e)}"
            }
    
    async def enrich_with_chromadb_context(
        self,
        query: str,
        agent_name: str,
        action: str,
        available_tools: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        TIER 2: Search ChromaDB for relevant context and re-analyze
        
        Args:
            query: Search query generated by Tier 1
            agent_name: Target agent
            action: Target action
            available_tools: Available tools
        
        Returns:
            Updated analysis with retrieved context
        """
        logger.info(f"[CONTEXT_ANALYZER] Enriching with ChromaDB context")
        logger.info(f"[CONTEXT_ANALYZER] Query: {query}")
        
        # Search ChromaDB for relevant contexts
        contexts = await self.retrieval_service.search_chromadb(
            query=query,
            agent_type=agent_name,
            top_k=5,
            min_relevance=0.5
        )
        
        if not contexts:
            logger.info("[CONTEXT_ANALYZER] No relevant context found in ChromaDB")
            return {
                "need_context": True,
                "context_source": "chromadb",
                "contexts_found": 0,
                "reason": "No relevant context in ChromaDB"
            }
        
        logger.info(f"[CONTEXT_ANALYZER] Found {len(contexts)} relevant context(s)")
        
        # Format contexts for LLM
        formatted_context = self.retrieval_service.format_context_for_llm(contexts)
        
        # Find tool info
        tool_info = self._get_tool_info(available_tools, action)
        
        # Build enrichment prompt
        prompt = self._build_context_enrichment_prompt(
            query=query,
            agent_name=agent_name,
            action=action,
            tool_info=tool_info,
            retrieved_context=formatted_context
        )
        
        # Call LLM to re-analyze with context
        try:
            response = await self.llm_service.call_ollama(
                model_name=self.model,
                prompt=prompt
            )
            
            logger.info(f"[CONTEXT_ANALYZER] LLM Enrichment Response: {response}")
            
            # Parse response
            analysis = self._parse_llm_response(response)
            
            if analysis:
                analysis["context_source"] = "chromadb"
                analysis["contexts_found"] = len(contexts)
                analysis["contexts"] = contexts
                logger.info(f"[CONTEXT_ANALYZER] ✅ Enrichment complete: need_context={analysis.get('need_context')}")
                return analysis
            else:
                return {
                    "need_context": True,
                    "context_source": "chromadb",
                    "contexts_found": len(contexts),
                    "reason": "Failed to parse enrichment response"
                }
                
        except Exception as e:
            logger.error(f"[CONTEXT_ANALYZER] ❌ Enrichment error: {e}", exc_info=True)
            return {
                "need_context": True,
                "context_source": "chromadb",
                "contexts_found": len(contexts),
                "reason": f"Enrichment error: {str(e)}"
            }
    
    async def enrich_with_agent_context(
        self,
        query: str,
        agent_name: str,
        action: str,
        available_tools: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        TIER 3: Request context from other agents and re-analyze
        
        Args:
            query: Query for context
            agent_name: Current agent
            action: Target action
            available_tools: Available tools
        
        Returns:
            Updated analysis with cross-agent context
        """
        logger.info(f"[CONTEXT_ANALYZER] Enriching with cross-agent context")
        
        # First, identify which agent might have relevant context
        target_agent_result = await self._identify_target_agent(query, agent_name)
        
        if not target_agent_result.get("need_context"):
            # LLM found sufficient info to determine target agent
            target_agent = target_agent_result.get("target_agent")
            
            if not target_agent or target_agent == agent_name:
                logger.info("[CONTEXT_ANALYZER] No suitable target agent found")
                return {
                    "need_context": True,
                    "context_source": "agent",
                    "reason": "No suitable agent identified for context"
                }
            
            logger.info(f"[CONTEXT_ANALYZER] Requesting context from {target_agent} agent")
            
            # Request context from target agent
            agent_context_result = await self.retrieval_service.request_agent_context(
                target_agent=target_agent,
                query=query,
                top_k=3
            )
            
            if not agent_context_result["success"]:
                logger.warning(f"[CONTEXT_ANALYZER] Failed to get context from {target_agent}")
                return {
                    "need_context": True,
                    "context_source": "agent",
                    "target_agent": target_agent,
                    "reason": agent_context_result.get("message", "No context from agent")
                }
            
            logger.info(f"[CONTEXT_ANALYZER] Retrieved {agent_context_result['context_count']} context(s) from {target_agent}")
            
            # Format agent context
            formatted_context = agent_context_result["formatted_context"]
            
            # Find tool info
            tool_info = self._get_tool_info(available_tools, action)
            
            # Build final enrichment prompt
            prompt = self._build_agent_enrichment_prompt(
                query=query,
                agent_name=agent_name,
                action=action,
                tool_info=tool_info,
                source_agent=target_agent,
                retrieved_context=formatted_context
            )
            
            # Call LLM for final analysis
            try:
                response = await self.llm_service.call_ollama(
                    model_name=self.model ,
                    prompt=prompt
                )
                
                logger.info(f"[CONTEXT_ANALYZER] LLM Agent Enrichment Response: {response}")
                
                # Parse response
                analysis = self._parse_llm_response(response)
                
                if analysis:
                    analysis["context_source"] = "agent"
                    analysis["source_agent"] = target_agent
                    analysis["contexts_found"] = agent_context_result["context_count"]
                    analysis["contexts"] = agent_context_result["contexts"]
                    logger.info(f"[CONTEXT_ANALYZER] ✅ Agent enrichment complete: need_context={analysis.get('need_context')}")
                    return analysis
                else:
                    return {
                        "need_context": True,
                        "context_source": "agent",
                        "target_agent": target_agent,
                        "reason": "Failed to parse agent enrichment response"
                    }
                    
            except Exception as e:
                logger.error(f"[CONTEXT_ANALYZER] ❌ Agent enrichment error: {e}", exc_info=True)
                return {
                    "need_context": True,
                    "context_source": "agent",
                    "target_agent": target_agent,
                    "reason": f"Enrichment error: {str(e)}"
                }
        
        else:
            # LLM couldn't determine target agent
            return {
                "need_context": True,
                "context_source": "agent",
                "reason": "Could not identify target agent for context"
            }
    
    async def generate_missing_context_message(
        self,
        agent_name: str,
        action: str,
        missing_params: Optional[List[str]] = None,
        query: Optional[str] = None
    ) -> str:
        """
        TIER 4: Generate user-friendly message for missing context
        
        Args:
            agent_name: Agent that needs context
            action: Action that cannot be completed
            missing_params: List of missing parameters
            query: Original query
        
        Returns:
            User-friendly message explaining what's missing
        """
        logger.info(f"[CONTEXT_ANALYZER] Generating missing context message for {agent_name}.{action}")
        
        # Build message based on agent and action
        if missing_params:
            params_str = ", ".join(missing_params)
            message = (
                f"I need more information to {action.replace('_', ' ')}. "
                f"Please provide: {params_str}."
            )
        else:
            message = (
                f"I don't have enough context to {action.replace('_', ' ')}. "
                f"Could you provide more details?"
            )
        
        logger.info(f"[CONTEXT_ANALYZER] Generated message: {message}")
        return message
    
    # ==================== HELPER METHODS ====================
    
    def _get_tool_info(
        self,
        available_tools: List[Dict[str, Any]],
        action: str
    ) -> Optional[Dict[str, Any]]:
        """Find tool definition by action name"""
        for tool in available_tools:
            if tool.get("name") == action:
                return tool
        return None
    
    def _build_context_analysis_prompt(
        self,
        user_input: str,
        agent_name: str,
        action: str,
        tool_info: Dict[str, Any]
    ) -> str:
        """Build prompt for Tier 1 context analysis"""
        
        # Extract required parameters from tool
        parameters = tool_info.get("parameters", {})
        required_params = parameters.get("required", [])
        
        prompt = f"""You are a context analyzer. Analyze if the user input contains ALL required information for this action.

**User Input:** {user_input}

**Agent:** {agent_name}
**Action:** {action}
**Description:** {tool_info.get('description', 'N/A')}

**Required Parameters:**
{self._format_parameters(parameters, required_params)}

**Your Task:**
1. Check if ALL required parameters can be extracted from user input
2. If YES: Return instructions for the agent
3. If NO: Return what context is missing

**Response Format (JSON only, no extra text):**

If sufficient context:
{{"need_context": false, "action": "{action}", "instructions": "Clear instructions for agent"}}

If missing context:
{{"need_context": true, "query": "semantic search query", "missing_params": ["param1", "param2"], "reason": "explanation"}}

**Rules:**
- Only return JSON, no markdown or extra text
- Be strict about required parameters
- Query should be natural language for semantic search
- Instructions should be clear and actionable

Respond:"""
        
        return prompt
    
    def _build_context_enrichment_prompt(
        self,
        query: str,
        agent_name: str,
        action: str,
        tool_info: Dict[str, Any],
        retrieved_context: str
    ) -> str:
        """Build prompt for Tier 2 ChromaDB enrichment"""
        
        parameters = tool_info.get("parameters", {})
        required_params = parameters.get("required", [])
        
        prompt = f"""You are a context analyzer. You searched for context and found relevant information.

**Original Query:** {query}

**Agent:** {agent_name}
**Action:** {action}

**Required Parameters:**
{self._format_parameters(parameters, required_params)}

{retrieved_context}

**Your Task:**
Analyze if the retrieved context provides enough information to complete the action.

**Response Format (JSON only):**

If sufficient:
{{"need_context": false, "action": "{action}", "instructions": "instructions based on context"}}

If still insufficient:
{{"need_context": true, "query": "refined search query", "reason": "what's still missing"}}

Respond:"""
        
        return prompt
    
    def _build_agent_enrichment_prompt(
        self,
        query: str,
        agent_name: str,
        action: str,
        tool_info: Dict[str, Any],
        source_agent: str,
        retrieved_context: str
    ) -> str:
        """Build prompt for Tier 3 agent context enrichment"""
        
        parameters = tool_info.get("parameters", {})
        required_params = parameters.get("required", [])
        
        prompt = f"""You are a context analyzer. Context was retrieved from {source_agent} agent.

**Original Need:** {query}

**Target Agent:** {agent_name}
**Action:** {action}

**Required Parameters:**
{self._format_parameters(parameters, required_params)}

**Context from {source_agent.upper()} Agent:**
{retrieved_context}

**Your Task:**
Analyze if the agent's context provides enough information.

**Response Format (JSON only):**

If sufficient:
{{"need_context": false, "action": "{action}", "instructions": "instructions using agent context"}}

If still insufficient:
{{"need_context": true, "reason": "specific missing information", "missing_params": ["param1"]}}

Respond:"""
        
        return prompt
    
    async def _identify_target_agent(
        self,
        query: str,
        current_agent: str
    ) -> Dict[str, Any]:
        """Identify which agent might have relevant context"""
        
        # Get all available agents
        available_agents = agent_registry.list_agents()
        
        # Build agent list with descriptions
        agents_info = []
        for agent_data in available_agents:
            agent_name = agent_data.get("name", "")
            if agent_name != current_agent:
                agents_info.append({
                    "name": agent_name,
                    "description": agent_data.get("description", "")
                })
        
        agents_str = "\n".join([
            f"- {a['name']}: {a['description']}" 
            for a in agents_info
        ])
        
        prompt = f"""You are an agent coordinator. Identify which agent might have relevant context.

**Context Need:** {query}
**Current Agent:** {current_agent}

**Available Agents:**
{agents_str}

**Task:** Which agent most likely has context for this need?

**Response (JSON only):**

If clear target:
{{"need_context": false, "target_agent": "agent_name", "reason": "why this agent"}}

If unclear:
{{"need_context": true, "reason": "cannot determine agent"}}

Respond:"""
        
        try:
            response = await self.llm_service.call_ollama(
                model_name=self.model ,
                prompt=prompt
            )
            
            return self._parse_llm_response(response) or {"need_context": True}
            
        except Exception as e:
            logger.error(f"[CONTEXT_ANALYZER] Error identifying target agent: {e}")
            return {"need_context": True}
    
    def _format_parameters(
        self,
        parameters: Dict[str, Any],
        required_params: List[str]
    ) -> str:
        """Format parameters for prompt"""
        props = parameters.get("properties", {})
        
        formatted = []
        for param_name, param_info in props.items():
            required_marker = "✓ REQUIRED" if param_name in required_params else "○ Optional"
            description = param_info.get("description", "No description")
            formatted.append(f"  - {param_name} [{required_marker}]: {description}")
        
        return "\n".join(formatted) if formatted else "  No parameters defined"
    
    def _parse_llm_response(self, response: str) -> Optional[Dict[str, Any]]:
        """Parse JSON from LLM response"""
        try:
            # Try direct JSON parse
            response = response.strip()
            
            # Extract JSON if wrapped in markdown or text
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                response = json_match.group(0)
            
            parsed = json.loads(response)
            return parsed
            
        except json.JSONDecodeError as e:
            logger.error(f"[CONTEXT_ANALYZER] JSON parse error: {e}")
            logger.error(f"[CONTEXT_ANALYZER] Raw response: {response}")
            return None


# Singleton getter
_context_analyzer: Optional[ContextAnalyzer] = None


def get_context_analyzer(llm_service: LLMService) -> ContextAnalyzer:
    """
    Get or create singleton instance of ContextAnalyzer
    
    Args:
        llm_service: LLM service instance
    
    Returns:
        ContextAnalyzer instance
    """
    global _context_analyzer
    
    if _context_analyzer is None:
        _context_analyzer = ContextAnalyzer(llm_service)
    
    return _context_analyzer
